#-*- coding:UTF-8 -*-
import os
from lxml import etree
from datatools.batch.common import XPather
from datatools.batch import common
from ckanext.canada.metadata_schema import schema_description as schema


nspace = common.nap_namespaces
presentationCodes = dict((choice['id'],choice['key']) for choice in schema.dataset_field_by_id['presentation_form']['choices'])


doc=None

def get_keywords(path):
                keywords = doc.xpath(path,namespaces=nspace)
                keywords_fr = doc_fr.xpath('//gmd:descriptiveKeywords/gmd:MD_Keywords/gmd:keyword/gco:CharacterString',namespaces=nspace)
           
                en_tags = [clean_tag(t.text) for t in keywords]  # must remove forward slashes to pass validation
                
                # Get rid of commans in keywords if they exist
                #en_tags = [tag.strip() for orig in en_tags for tag in orig.split(",")]
                fr_tags = [clean_tag(t.text) for t in keywords_fr]
                #fr_tags = [tag.strip() for orig in fr_tags for tag in orig.split(",")]
                #tags = [{'name': clean_tag(en) + u'  ' + clean_tag(fr)} for en, fr in zip(en_tags, fr_tags) if clean_tag(en) and (len(clean_tag(en)) + len(clean_tag(fr))) < 96]
    
                #package_dict['tags'] = tags
                # Tags are now gone, replaced by en, fr lists of comma delimited keywords
               
                package_dict['keywords'] = ",".join(en_tags)
                package_dict['keywords_fra'] = ",".join(fr_tags)

def get_presentation_code():
    try:
        pCode = doc.xpath('//gmd:CI_PresentationFormCode',namespaces=nspace)[0].attrib['codeListValue'].split("_")[1]
        pName = presentationCodes[int(pCode)]
        return pName
    except IndexError:
        print "No presentation Form"
        return presentationCodes[387]
    except KeyError:
        print "Presentation code not in Schema"
        return ''
 

def full_path(path):
    return doc.xpath((path),namespaces=nspace)[0].text

def charstring_path(key):
    return doc.xpath(('//gmd:%s/gco:CharacterString' % key),namespaces=nspace)[0].text
                

package_dict = {'resources': [], 'tags':[]}  

def resources():
    resource_dict['name']
    resource_dict['name_fra']
    resource_dict['resource_type']
    resource_dict['url']
    resource_dict['size']
    resource_dict['format']
    resource_dict['language']

def data_identification():
    #12 of 45
    package_dict['id'] = charstring_path('fileIdentifier')
    package_dict['language']=schema.dataset_field_by_id['language']['example']['eng']
    package_dict['owner_org']='nrcan-rncan'
    package_dict['author_email']=charstring_path('electronicMailAddress')             
    #package_dict['name']   type: calculated
    package_dict['catalog_type']=u"Geo Data | G\xe9o"
    #package_dict['subject']  only used in pilot
    #MISSING package_dict['topic_category']  #//gmd:MD_TopicCategoryCode is missing from the new XML format
    package_dict['license_id']="ca-ogl-lgo"
    package_dict['presentation_form']=get_presentation_code()
    #MISSING package_dict['browse_graphic_url']
    package_dict['digital_object_identifier']

def time_and_space():
    #11 of 45
    package_dict['date_published']
    package_dict['date_modified']
    package_dict['maintenance_and_update_frequency']
    package_dict['validation_override']=True  
    package_dict['portal_release_date']='2013-05-24'
    package_dict['ready_to_publish']=True
    package_dict['time_period_coverage_start']
    package_dict['time_period_coverage_end']  
    package_dict['geographic_region']
    package_dict['spatial']
    package_dict['spatial_representation_type']   

def bilingual():
    # 14 of 45
    #package_dict['attribution']  Generated by ckanext-canada
    #package_dict['attribution_fr'] Generated by ckanext-canada
    package_dict['data_series_name']=full_path('//gmd:CI_Citation/gmd:series/gmd:CI_Series/gmd:name/gco:CharacterString')
    package_dict['data_series_name_fra']=full_path('//gmd:CI_Citation/gmd:series/gmd:CI_Series/gmd:name/gmd:PT_FreeText/gmd:textGroup/gmd:LocalisedCharacterString')
    package_dict['data_series_issue_identification']=full_path('gmd:MD_Metadata/gmd:identificationInfo/gmd:MD_DataIdentification/gmd:citation/gmd:CI_Citation/gmd:series/gmd:CI_Series/gmd:issueIdentification')
    package_dict['data_series_issue_identification_fra']='gmd:MD_Metadata/gmd:identificationInfo/gmd:MD_DataIdentification/gmd:citation/gmd:CI_Citation/gmd:series/gmd:CI_Series/gmd:issueIdentification'
    package_dict['endpoint_url']='http://geogratis.gc.ca/api/en/nrcan-rncan/ess-sst/'
    package_dict['endpoint_url_fra']='http://geogratis.gc.ca/api/fr/nrcan-rncan/ess-sst/'
    package_dict['keywords']=keywords('//gmd:keyword/gco:CharacterString')
    package_dict['keywords_fra']=keywords('//gmd:keyword/gmd:PT_FreeText/gmd:textGroup/gmd:LocalisedCharacterString')

    def get_notes(path):
        try:
            notes = doc.xpath(path)[0].text
            if 'Abstract not available' in notes:
                notes="Abstract not available."
            if 'Résumé non disponible' in notes:
                notes=u"Résumé non disponible."
            return notes
        except:
            raise

    package_dict['notes']=get_notes('//gmd:abstract/gco:CharacterString')
    package_dict['notes_fra'] =get_notes('gmd:abstract:/gmd:PT_FreeText/gmd:textGroup/gmd:LocalisedCharacterString') 
    package_dict['title'] = full_path('gmd:MD_Metadata/gmd:identificationInfo/gmd:MD_DataIdentification/gmd:citation/gmd:CI_Citation/gmd:title/gco:CharacterString')
    package_dict['title_fra'] = full_path('gmd:MD_Metadata/gmd:identificationInfo/gmd:MD_DataIdentification/gmd:citation/gmd:CI_Citation/gmd:title/gmd:PT_FreeText/gmd:textGroup/gmd:LocalisedCharacterString')
                    
def process(dir): 
    global doc
    for (path, dirs, files) in os.walk(os.path.normpath(dir)):
        for n,file in enumerate(files):
            
            f = open(os.path.join(path,file),"r")
            doc = etree.parse(f)
            data_identification()
            tim_and_space()
            bilingual()
            resources()
            pprint(package_dict)
            if (n % 100) == 0: print n 

            #jlfile.write(json.dumps(package_dict) + "\n")  


if __name__ == "__main__":
    dir="/Users/peder/dev/OpenData/nrcandump-sample"
    process(dir)
        
    ''' 
    RESOURCE:
        1 name
        2 name_fra
        3 resource_type
        4 url
        5 size
        6 format
        7 language
    DATASET:
        1 id
        2 language
        3 owner_org
        4 author_email
        5 title
        6 title_fra
        7 name
        8 notes
        9 notes_fra
        10 catalog_type
        11 subject
        12 topic_category
        13 keywords
        14 keywords_fra
        15 license_id
        16 attribution
        17 attribution_fra
        18 geographic_region
        19 spatial
        20 spatial_representation_type
        21 presentation_form
        22 browse_graphic_url
        23 date_published
        24 date_modified
        25 maintenance_and_update_frequency
        26 data_series_name
        27 data_series_name_fra
        28 data_series_issue_identification
        29 data_series_issue_identification_fra
        30 digital_object_identifier
        31 time_period_coverage_start
        32 time_period_coverage_end
        33 url
        34 url_fra
        35 endpoint_url
        36 endpoint_url_fra
        37 ready_to_publish
        38 portal_release_date
    '''
    #process()